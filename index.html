<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kenneth Yang</title>

    <meta name="author" content="Kenneth Yang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:95%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:95%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">


              <td style="padding:2.5%;width:70%;vertical-align:middle">  <!-- Text wider -->
                <p class="name" style="text-align: center;">
                  Kenneth Yang
                </p>

                <p style="text-align:center;">
                  <strong style="color:red;">I am actively seeking research intern opportunities!</strong>
                </p>

                <p>
                  I received my B.S. degree in Computer Science from <a>National Tsing Hua University</a>, where I was a <strong>Dean's List Award (Top 5%) recipient twice</strong>. 
                  <!-- During undergrad, I worked with <a href="https://aliensunmin.github.io/">Prof. Min Sun</a> on multi-view layout estimation, assisted in organizing the <a href="https://omnivision.github.io/OmniCV-Workshop-2023/">First Multi-View Layout Estimation Challenge</a> at CVPR 2023, and conducted independent research on integrating multi-view predictions. -->
                </p>
                <p>
                  During undergrad, I worked as a research assistant at <a href="https://www.iis.sinica.edu.tw/">Academia Sinica</a> with <a href="https://sites.google.com/site/jenchunlin/">Dr. Jen-Chun Lin</a>, focusing on PEFT and multi-modal retrieval, including a <strong>ICASSP 2024 oral</strong> and a <strong>planned NeurIPS 2025 submission</strong>.
                  I also collaborated with <a href="https://aliensunmin.github.io/">Prof. Min Sun</a> on multi-view layout estimation and assisted in organizing the <a href="https://mvlchallenge.github.io/">First Multi-View Layout Estimation Challenge</a> at CVPR 2023.
                </p>
                <p>
                  Currently, I am a research assistant at the <a href="https://vllab.ee.ntu.edu.tw/">Vision & Learning Lab, National Taiwan University</a>, supervised by <a href="https://vllab.ee.ntu.edu.tw/ycwang.html">Prof. Yu-Chiang Frank Wang</a>, Director of NVIDIA Research Taiwan. My research centers on 3D vision and Gaussian Splatting.
                </p>
                
                <p style="text-align:center">
                  <a href="mailto:s109062136@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="Kenneth__Resume___20240317.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <!-- <a href="https://bsky.app/profile/jonbarron.bsky.social">Bluesky</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/CSYangHsu">Github</a>
                </p>
              </td>


              <td style="padding:2.5%;width:30%;max-width:30%">        <!-- Image narrower -->
                <a href="images/kenneth/myself.png">
                  <img 
                    style="width:80%; max-width:300px; object-fit:contain;" 
                    alt="profile photo" 
                    src="images/kenneth/myself.png">
                </a>
              </td>
            </tr>
          </tbody></table>

          <!-- Institute Logos Row -->
          <table style="width:95%;border:0px;margin-top:20px;margin-bottom:20px;">
            <tbody>
              <tr style="text-align:center;">
                <!-- NTU VLLab -->
                <td style="padding:10px;">
                  <img src="images\kenneth\institute\NTU.png" style="width:190px;"><br>
                  <span style="font-size:14px;"><strong>NTU VLLab</strong><br>Research Assistant<br>Sep '24 – Present</span>
                </td>
          
                <!-- Academia Sinica -->
                <td style="padding:10px;">
                  <img src="images\kenneth\institute\IIS.png" style="width:190px;"><br>
                  <span style="font-size:14px;"><strong>Academia Sinica</strong><br>Research Intern / RA<br>Jul '23 – Dec '24</span>
                </td>
          
                <!-- NTHU Vision Lab -->
                <td style="padding:10px;">
                  <img src="images\kenneth\institute\NTHU.png" style="width:190px;"><br>
                  <span style="font-size:14px;"><strong>NTHU VSLab</strong><br>Undergraduate Student<br>Aug '23 – Jun '24</span>
                </td>
              </tr>
            </tbody>
          </table>
          

          <table style="width:95%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:95%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in the intersection of computer vision and deep learning, particularly in <strong>PEFT (Parameter-Efficient Fine-Tuning)</strong> and <strong>3D vision</strong>. 
                  <!-- My research focuses on developing efficient fine-tuning methods and advancing large-scale 3D scene understanding. -->
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:95%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<!-- 

    <tr onmouseout="power_stop()" onmouseover="power_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='power_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/power.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/power.png' width="160">
        </div>
        <script type="text/javascript">
          function power_start() {
            document.getElementById('power_image').style.opacity = "1";
          }

          function power_stop() {
            document.getElementById('power_image').style.opacity = "0";
          }
          power_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://x.com/jon_barron/status/1891918200931061996">
			<span class="papertitle">A Power Transform
</span>
        </a>
        <br>
				<strong>Jonathan T. Barron</strong>
        <br>
        <em>arXiv</em>, 2025
        <br>
        <a href="https://x.com/jon_barron/status/1891918200931061996">tweet</a>
        /
        <a href="https://arxiv.org/abs/2502.10647">arXiv</a>
        <p></p>
        <p>
				A slight tweak to the Box-Cox power transform generalizes a variety of curves, losses, kernel functions, probability distributions, bump functions, and neural network activation functions.
        </p>
      </td>
    </tr>


    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
          <source src="images/r2r.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/r2r.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://relight-to-reconstruct.github.io/">
          <span class="papertitle">Generative Multiview Relighting for
3D Reconstruction under Extreme Illumination Variation</span>
        </a>
        <br>
        <a href="https://hadizayer.github.io/">Hadi Alzayer</a>,
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
				<strong>Jonathan T. Barron</strong>, 
        <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>, 
        <a href="https://dorverbin.github.io/">Dor Verbin</a>
        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://relight-to-reconstruct.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
        <p></p>
        <p>
				Images taken under extreme illumination variation can be made consistent with diffusion, and this enables high-quality 3D reconstruction.
        </p>
      </td>
    </tr> -->





    <tr>
      <!-- Left column: Placeholder image -->
      <td style="padding:16px;width:35%;vertical-align:middle">
        <img src='papers/FPS/textimg.png' width=100%> <!-- Replace with actual image path if available -->
      </td>
    
      <!-- Right column: Paper details -->
      <td style="padding:8px;width:80%;vertical-align:middle">
        <!-- Paper title -->
        <a> <!-- Replace with real arXiv link -->
          <span class="papertitle">FPS: Feed-Forward Based Parameter Selection for Efficient Fine-Tuning</span>
        </a>
        
        <br>
        <!-- Author list -->
        <strong>Kenneth Yang</strong>, 
        <a href="https://sites.google.com/site/jenchunlin/">Jen-Chun Lin</a>
        <br>
        <em>NeurIPS</em>, 2025 Planned Submission
        <br>
        <!-- Description -->
        <p>
          Designing FPS, a novel feed-forward based parameter selection framework that identifies and updates the most impactful parameters during fine-tuning, reducing computational cost without sacrificing model performance. Achieves <strong>SOTA</strong> performance with only <strong>10% memory usage</strong> on large benchmarks such as FGVC and VTAB-1k. Manuscript in preparation for submission to NeurIPS 2025.
        </p>
      </td>
    </tr>
    
    









    <tr>
      <!-- Left column: Paper image -->
      <td style="padding:16px;width:35%;vertical-align:middle">
        <img src='papers/ICASSP24_music2pose/overview.png' width=100%>
      </td>
    
      <!-- Right column: Paper details -->
      <td style="padding:8px;width:80%;vertical-align:middle">
        <!-- Paper title -->
        <a href="https://ieeexplore.ieee.org/document/10446425"> <!-- Replace with real arXiv link -->
          <span class="papertitle">MUSIC-TO-DANCE POSES: Learning to Retrieve Dance Poses from Music</span>
        </a>
        <br>
        <!-- Author list -->
        Bo-Wei Tseng, 
        <strong>Kenneth Yang</strong>, 
        Yu-Hua Hu, 
        Wen-Li Wei, 
        <a href="https://sites.google.com/site/jenchunlin/">Jen-Chun Lin</a>
        <br>
        <em>ICASSP</em>, 2024 Oral
        <br>
        <!-- Links -->
        <a href="https://ieeexplore.ieee.org/document/10446425">paper</a>  <!-- Replace -->
        <!-- Description -->
        <p>
          Developed a music-to-dance pose retrieval system matching 3D human poses and shapes from musical snippets, integrating novel fine-tuning techniques for cross-modal retrieval.
        </p>
      </td>
    </tr>
    
<!-- 
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a>
								<br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a>
								<br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a>
								<br>
								<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a>
								<br>
								<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr> -->
            
          </tbody></table>
          <table style="width:95%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:13px; text-align:center;">
                  <p style="font-size:13px;">
                    Website template adapted from 
                    <a href="https://jonbarron.info/" style="font-size:13px;">Jon Barron</a>. 
                    You can find the original source code 
                    <a href="https://github.com/jonbarron/jonbarron_website" style="font-size:13px;">here</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
    </table>
  </body>
</html>
